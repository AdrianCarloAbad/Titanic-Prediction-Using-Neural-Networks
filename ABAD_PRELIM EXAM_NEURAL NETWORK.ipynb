{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788475bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Dense' from 'keras' (C:\\Users\\asus\\anaconda3\\lib\\site-packages\\keras\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Import libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Dense' from 'keras' (C:\\Users\\asus\\anaconda3\\lib\\site-packages\\keras\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "from keras import Sequential\n",
    "from keras import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2baa1753",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mDense\u001b[49m(\u001b[38;5;241m12\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m8\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dense' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making of models\n",
    "model.add(Dense(12, input_shape=(8,), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b339ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01577ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a699bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_variables, y_variable, epochs=100, batch_size=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the accuracy rate\n",
    "_, accuracy = model.evaluate(x_variables, y_variable)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison\n",
    "# The K-Nearest Neighbor (KNN) algorithm determines the similarities of a certain variable between two given datasets. There are categories that will be a basis where the variable belongs. Also, this algorithm is the best when the user utilizes small datasets. On the other hand, the Logistic Regression algorithm utilizes probability in determining whether certain data falls into a type of classification. The difference between logistic regression and KNN is that logistic regression utilizes large datasets. In the accuracy part, the result of logistic regression is more accurate which is, 70%-80% while KNN has a 66%-75% accuracy rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53645af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis\n",
    "#The goal of the program is to determine who are the individuals that can survive the Titanic tragedy. There is a part of the dataset that is not needed. In order to detect the gaps in the data, I used the “isna” function. In the use of this function, the data is organized and clean wherein the application of machine learning in the program will be easier. Also, the “inplace” function was used to change the given values to numerical form. This would allow the program to interpret the data. Lastly, the application of the algorithms was used to determine the accuracy rate. The trained dataset is already modified and the prediction of machine learning will execute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion\n",
    "#In conclusion, I was able to create two machine learning algorithm programs that determine the kind of individuals who are more likely to survive in the Titanic voyage. The two machine learning algorithms chosen are K-Nearest Neighbor (KNN) and Logistic Regression. I imported some necessary libraries needed to the program such as Pandas and NumPy. I also used the dataset of titanic passengers from Kaggle which determines the age, fare, names, etc. of each individual. In order to find the accuracy rate of each program, I modified the dataset and remove the unnecessary data. Also, I turned the NaN values to zero to clean it. After modifying the data, I applied the algorithm to get the accuracy rate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
